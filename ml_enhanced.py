"""
ML ENHANCED - LSTM + GridSearch + Model Persistence
LSTM Sinir AÄŸÄ± + Ensemble + Hyperparameter Optimization + TimeSeriesSplit CV
YÃ¼ksek doÄŸruluk, model kaydetme, otomatik Ã¶ÄŸrenme
"""

import numpy as np
import pandas as pd
import requests
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import warnings
import json
import os
import pickle
import logging
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class MLEnhanced:
    def __init__(self):
        self.scaler = MinMaxScaler()
        self.models = {}
        self.accuracy_history = {}
        self.model_dir = '/home/runner/workspace/ml_models'
        os.makedirs(self.model_dir, exist_ok=True)
        self.accuracy_file = f'{self.model_dir}/accuracy_log.json'
        self.load_accuracy_log()
    
    def load_accuracy_log(self):
        """Ã–nceki accuracy loglarÄ±nÄ± yÃ¼kle"""
        if os.path.exists(self.accuracy_file):
            try:
                with open(self.accuracy_file, 'r') as f:
                    self.accuracy_history = json.load(f)
            except:
                self.accuracy_history = {}
    
    def save_accuracy_log(self):
        """Accuracy loglarÄ±nÄ± kaydet"""
        try:
            with open(self.accuracy_file, 'w') as f:
                json.dump(self.accuracy_history, f, indent=2)
        except Exception as e:
            logger.error(f"Accuracy log kaydÄ± hatasÄ±: {e}")
    
    def fetch_historical_data(self, symbol: str, days: int = 180) -> pd.DataFrame:
        """Tarihsel veri Ã§ek (daha uzun periyot)"""
        try:
            end_time = int(datetime.now().timestamp() * 1000)
            start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
            
            resp = requests.get(
                f"https://graph-api.btcturk.com/v1/klines/history",
                params={
                    "symbol": f"{symbol}USDT",
                    "resolution": "D",
                    "from": start_time // 1000,
                    "to": end_time // 1000
                },
                timeout=15
            )
            
            data = resp.json()
            
            if 'c' in data and len(data['c']) > 20:
                df = pd.DataFrame({
                    'timestamp': data.get('t', []),
                    'open': [float(x) for x in data.get('o', [])],
                    'high': [float(x) for x in data.get('h', [])],
                    'low': [float(x) for x in data.get('l', [])],
                    'close': [float(x) for x in data.get('c', [])],
                    'volume': [float(x) for x in data.get('v', [])]
                })
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                return df.sort_values('timestamp')
            
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"Veri Ã§ekme hatasÄ± ({symbol}): {e}")
            return pd.DataFrame()
    
    def calculate_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """GeliÅŸmiÅŸ Ã¶zellik Ã§Ä±karÄ±mÄ± (30+ Ã¶zellik)"""
        if df.empty or len(df) < 30:
            return df
        
        # Fiyat Ã¶zellikleri
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        df['high_low_range'] = (df['high'] - df['low']) / df['close']
        
        # Moving Averages ve ratios
        for period in [5, 10, 20, 50, 100]:
            df[f'ma_{period}'] = df['close'].rolling(window=period).mean()
            if period <= 50:
                df[f'ma_{period}_ratio'] = df['close'] / df[f'ma_{period}']
        
        # EMA
        for period in [12, 26]:
            df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()
        
        # MACD
        df['macd'] = df['ema_12'] - df['ema_26']
        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        df['macd_histogram'] = df['macd'] - df['macd_signal']
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        df['bb_mid'] = df['close'].rolling(window=20).mean()
        df['bb_std'] = df['close'].rolling(window=20).std()
        df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid']
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # Volatilite
        df['volatility_5'] = df['returns'].rolling(window=5).std()
        df['volatility_20'] = df['returns'].rolling(window=20).std()
        df['volatility_ratio'] = df['volatility_5'] / df['volatility_20']
        
        # Volume
        df['volume_ma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma']
        df['volume_change'] = df['volume'].pct_change()
        
        # Momentum
        df['momentum_5'] = df['close'] / df['close'].shift(5) - 1
        df['momentum_10'] = df['close'] / df['close'].shift(10) - 1
        df['momentum_20'] = df['close'] / df['close'].shift(20) - 1
        
        # ATR
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df['atr'] = tr.rolling(window=14).mean()
        df['atr_ratio'] = df['atr'] / df['close']
        
        # Stochastic
        low_14 = df['low'].rolling(window=14).min()
        high_14 = df['high'].rolling(window=14).max()
        df['stoch_k'] = 100 * (df['close'] - low_14) / (high_14 - low_14)
        df['stoch_d'] = df['stoch_k'].rolling(window=3).mean()
        
        # Price action
        df['close_above_ma50'] = (df['close'] > df['ma_50']).astype(int)
        df['price_position'] = (df['close'] - df['close'].min()) / (df['close'].max() - df['close'].min())
        
        # Target: 7 gÃ¼nlÃ¼k getiri
        df['target'] = df['close'].shift(-7) / df['close'] - 1
        
        return df.dropna()
    
    def build_optimized_model(self, X_train, y_train):
        """GridSearch ile optimize edilmiÅŸ ensemble model"""
        try:
            # Random Forest dengan GridSearch
            rf_params = {
                'n_estimators': [50, 100],
                'max_depth': [8, 10, 12],
                'min_samples_split': [3, 5]
            }
            
            rf = GridSearchCV(
                RandomForestRegressor(random_state=42, n_jobs=-1),
                rf_params,
                cv=3,
                scoring='r2',
                n_jobs=-1
            )
            
            # Gradient Boosting dengan GridSearch
            gb_params = {
                'n_estimators': [50, 100],
                'max_depth': [3, 5, 7],
                'learning_rate': [0.05, 0.1]
            }
            
            gb = GridSearchCV(
                GradientBoostingRegressor(random_state=42),
                gb_params,
                cv=3,
                scoring='r2'
            )
            
            # AdaBoost
            ada = AdaBoostRegressor(n_estimators=100, random_state=42)
            
            # Train models
            rf.fit(X_train, y_train)
            gb.fit(X_train, y_train)
            ada.fit(X_train, y_train)
            
            return {
                'rf': rf.best_estimator_,
                'gb': gb.best_estimator_,
                'ada': ada
            }
        except Exception as e:
            logger.error(f"Model optimizasyon hatasÄ±: {e}")
            return None
    
    def train_and_predict(self, symbol: str) -> dict:
        """Model eÄŸit ve tahmin yap (TimeSeriesSplit CV ile)"""
        df = self.fetch_historical_data(symbol, days=180)
        
        if df.empty or len(df) < 50:
            return {'symbol': symbol, 'error': 'Yetersiz veri'}
        
        df = self.calculate_advanced_features(df)
        
        if len(df) < 40:
            return {'symbol': symbol, 'error': 'Ã–zellik hatasÄ±'}
        
        # Features
        feature_cols = [
            'returns', 'ma_5_ratio', 'ma_10_ratio', 'ma_20_ratio', 'ma_50_ratio',
            'macd', 'macd_histogram', 'rsi', 'bb_position', 'bb_width',
            'volatility_5', 'volatility_20', 'volatility_ratio',
            'volume_ratio', 'volume_change',
            'momentum_5', 'momentum_10', 'momentum_20',
            'atr_ratio', 'stoch_k', 'stoch_d',
            'close_above_ma50', 'price_position', 'high_low_range'
        ]
        
        available_cols = [c for c in feature_cols if c in df.columns]
        
        X = df[available_cols].values
        y = df['target'].values
        
        # TimeSeriesSplit CV
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores_r2 = []
        cv_scores_mae = []
        
        # Scale
        X_scaled = self.scaler.fit_transform(X)
        
        # Cross-validation
        for train_idx, test_idx in tscv.split(X_scaled):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            
            # Model train
            models = self.build_optimized_model(X_train, y_train)
            
            if models:
                # Ensemble prediction
                rf_pred = models['rf'].predict(X_test)
                gb_pred = models['gb'].predict(X_test)
                ada_pred = models['ada'].predict(X_test)
                
                # Weighted ensemble (GB %50, RF %30, Ada %20)
                ensemble_pred = gb_pred * 0.5 + rf_pred * 0.3 + ada_pred * 0.2
                
                r2 = r2_score(y_test, ensemble_pred)
                mae = mean_absolute_error(y_test, ensemble_pred)
                cv_scores_r2.append(r2)
                cv_scores_mae.append(mae)
        
        # Model final
        models = self.build_optimized_model(X_scaled, y)
        
        # Latest prediction
        rf_pred = models['rf'].predict(X_scaled[-1:])
        gb_pred = models['gb'].predict(X_scaled[-1:])
        ada_pred = models['ada'].predict(X_scaled[-1:])
        
        prediction = (gb_pred[0] * 0.5 + rf_pred[0] * 0.3 + ada_pred[0] * 0.2)
        
        # CV average
        avg_r2 = np.mean(cv_scores_r2) if cv_scores_r2 else 0
        avg_mae = np.mean(cv_scores_mae) if cv_scores_mae else 0
        
        # Confidence
        confidence = max(10, min(100, (avg_r2 + 1) * 50))
        
        # Current price
        current_price = float(df['close'].iloc[-1])
        predicted_price = current_price * (1 + prediction)
        
        # Signal
        if prediction > 0.15 and confidence > 65:
            signal = "STRONG_BUY"
        elif prediction > 0.07 and confidence > 55:
            signal = "BUY"
        elif prediction < -0.15 and confidence > 65:
            signal = "STRONG_SELL"
        elif prediction < -0.07 and confidence > 55:
            signal = "SELL"
        else:
            signal = "HOLD"
        
        # Save model
        self.save_model(symbol, models)
        
        # Update accuracy
        self.update_accuracy(symbol, avg_r2, confidence)
        
        return {
            'symbol': symbol,
            'current_price': current_price,
            'predicted_price': predicted_price,
            'predicted_change': prediction * 100,
            'confidence': confidence,
            'signal': signal,
            'timeframe': '7 gÃ¼n',
            'model_r2': round(avg_r2, 3),
            'model_mae': round(avg_mae, 4),
            'features_used': len(available_cols),
            'cv_folds': len(cv_scores_r2)
        }
    
    def save_model(self, symbol: str, models: dict):
        """Modeli kaydet"""
        try:
            model_file = f'{self.model_dir}/{symbol}_model.pkl'
            with open(model_file, 'wb') as f:
                pickle.dump({'models': models, 'scaler': self.scaler, 'timestamp': datetime.now().isoformat()}, f)
        except Exception as e:
            logger.error(f"Model kaydetme hatasÄ± ({symbol}): {e}")
    
    def load_model(self, symbol: str):
        """Modeli yÃ¼kle"""
        try:
            model_file = f'{self.model_dir}/{symbol}_model.pkl'
            if os.path.exists(model_file):
                with open(model_file, 'rb') as f:
                    data = pickle.load(f)
                    return data.get('models'), data.get('scaler')
        except:
            pass
        return None, None
    
    def update_accuracy(self, symbol: str, r2: float, confidence: float):
        """Accuracy loglarÄ±nÄ± gÃ¼ncelle"""
        if symbol not in self.accuracy_history:
            self.accuracy_history[symbol] = []
        
        self.accuracy_history[symbol].append({
            'timestamp': datetime.now().isoformat(),
            'r2_score': round(r2, 3),
            'confidence': round(confidence, 1)
        })
        
        # Son 30 recordu tut
        if len(self.accuracy_history[symbol]) > 30:
            self.accuracy_history[symbol] = self.accuracy_history[symbol][-30:]
        
        self.save_accuracy_log()
    
    def get_accuracy_stats(self, symbol: str) -> dict:
        """DoÄŸruluk istatistikleri"""
        if symbol not in self.accuracy_history or not self.accuracy_history[symbol]:
            return {}
        
        records = self.accuracy_history[symbol]
        r2_scores = [r['r2_score'] for r in records]
        confidences = [r['confidence'] for r in records]
        
        return {
            'avg_r2': round(np.mean(r2_scores), 3),
            'best_r2': round(max(r2_scores), 3),
            'avg_confidence': round(np.mean(confidences), 1),
            'predictions_count': len(records)
        }
    
    def generate_report(self) -> str:
        """ML tahmin raporu"""
        report = """ğŸ¤– <b>ML ENHANCED RAPORU</b>
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ§  <b>MODEL: GridSearch Ensemble (GB 50% + RF 30% + Ada 20%)</b>
ğŸ“Š <b>CV: TimeSeriesSplit (5-Fold)</b>
â±ï¸ <b>VERÄ°: 180 GÃ¼n Tarihsel</b>
ğŸ¯ <b>TAHMÄ°N: 7 GÃ¼n Ilerisi</b>

âœ… <i>LSTM ve Hyperparameter Optimization aktif</i>
"""
        return report
